{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f787dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import prettytable\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pygeoj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"https://mw-project-4.s3.us-west-1.amazonaws.com/mw_scraped_indeedjobs.csv\"\n",
    "bigcsv = pd.read_csv(filepath)\n",
    "alldf = bigcsv.sort_values('Job Category')\n",
    "df = alldf.rename(columns = {'Company Location': 'Area text'})\n",
    "df['Job Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a22bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[df['Area text'].str.contains(\", CA\")]\n",
    "df2=df[df['Area text'].str.contains(\"California\")]\n",
    "df3=df2[df2['Area text']!='California-Lexington Park, MD']\n",
    "dfca=pd.concat([df1, df3])\n",
    "dfca['Area text']=\"CA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", AL\")]\n",
    "df2=df[df['Area text'].str.contains(\"Alabama\")]\n",
    "dfal=pd.concat([df1, df2])\n",
    "dfal['Area text']=\"AL\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", AK\")]\n",
    "df2=df[df['Area text'].str.contains(\"Alaska\")]\n",
    "dfak=pd.concat([df1, df2])\n",
    "dfak['Area text']=\"AK\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", AZ\")]\n",
    "df2=df[df['Area text'].str.contains(\"Arizona\")]\n",
    "dfaz=pd.concat([df1, df2])\n",
    "dfaz['Area text']=\"AZ\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", AR\")]\n",
    "df2=df[df['Area text'].str.contains(\"Arkansas\")]\n",
    "dfar=pd.concat([df1, df2])\n",
    "dfar['Area text']=\"AR\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", CO\")]\n",
    "df2=df[df['Area text'].str.contains(\"Colorado\")]\n",
    "dfco=pd.concat([df1, df2])\n",
    "dfco['Area text']=\"CO\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", CT\")]\n",
    "df2=df[df['Area text'].str.contains(\"Connecticut\")]\n",
    "dfct=pd.concat([df1, df2])\n",
    "dfct['Area text']=\"CT\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", DE\")]\n",
    "df2=df[df['Area text'].str.contains(\"Delaware\")]\n",
    "dfde=pd.concat([df1, df2])\n",
    "dfde['Area text']=\"DE\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "# dfdc=df[df['Area text'].str.contains(\"District of Columbia\")]\n",
    "# dfdc['Area text']=\"DC\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", FL\")]\n",
    "df2=df[df['Area text'].str.contains(\"Florida\")]\n",
    "dffl=pd.concat([df1, df2])\n",
    "dffl['Area text']=\"FL\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", GA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Georgia\")]\n",
    "dfga=pd.concat([df1, df2])\n",
    "dfga['Area text']=\"GA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", HI\")]\n",
    "df2=df[df['Area text'].str.contains(\"Hawaii\")]\n",
    "dfhi=pd.concat([df1, df2])\n",
    "dfhi['Area text']=\"HI\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", ID\")]\n",
    "df2=df[df['Area text'].str.contains(\"Idaho\")]\n",
    "dfid=pd.concat([df1, df2])\n",
    "dfid['Area text']=\"ID\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", IL\")]\n",
    "df2=df[df['Area text'].str.contains(\"Illinois\")]\n",
    "dfil=pd.concat([df1, df2])\n",
    "dfil['Area text']=\"IL\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", IN\")]\n",
    "df2=df[df['Area text'].str.contains(\"Indiana\")]\n",
    "df3=df2[df2['Area text']!='Indianapolis-Carmel-Anderson, IN']\n",
    "dfin=pd.concat([df1, df3])\n",
    "dfin['Area text']=\"IN\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", IA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Iowa\")]\n",
    "df3=df2[df2['Area text']!=\"Iowa City, IA\"]\n",
    "dfia=pd.concat([df1, df3])\n",
    "dfia['Area text']=\"IA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", KS\")]\n",
    "df2=df[df['Area text'].str.contains(\"Kansas\")]\n",
    "dfks=pd.concat([df1, df2])\n",
    "dfks['Area text']=\"KS\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", KY\")]\n",
    "df2=df[df['Area text'].str.contains(\"Kentucky\")]\n",
    "dfky=pd.concat([df1, df2])\n",
    "dfky['Area text']=\"KY\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", LA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Louisiana\")]\n",
    "dfla=pd.concat([df1, df2])\n",
    "dfla['Area text']=\"LA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", ME\")]\n",
    "df2=df[df['Area text'].str.contains(\"Maine\")]\n",
    "dfme=pd.concat([df1, df2])\n",
    "dfme['Area text']=\"ME\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MD\")]\n",
    "df2=df[df['Area text'].str.contains(\"Maryland\")]\n",
    "dfmd=pd.concat([df1, df2])\n",
    "dfmd['Area text']=\"MD\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Massachusetts\")]\n",
    "dfma=pd.concat([df1, df2])\n",
    "dfma['Area text']=\"MA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MI\")]\n",
    "df2=df[df['Area text'].str.contains(\"Michigan\")]\n",
    "df3=df2[df2['Area text']!='Michigan City-La Porte, IN']\n",
    "dfmi=pd.concat([df1, df3])\n",
    "dfmi['Area text']=\"MI\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MN\")]\n",
    "df2=df[df['Area text'].str.contains(\"Minnesota\")]\n",
    "dfmn=pd.concat([df1, df2])\n",
    "dfmn['Area text']=\"MN\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MS\")]\n",
    "df2=df[df['Area text'].str.contains(\"Mississippi\")]\n",
    "dfms=pd.concat([df1, df2])\n",
    "dfms['Area text']=\"MS\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MO\")]\n",
    "df2=df[df['Area text'].str.contains(\"Missouri\")]\n",
    "dfmo=pd.concat([df1, df2])\n",
    "dfmo['Area text']=\"MO\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MT\")]\n",
    "df2=df[df['Area text'].str.contains(\"Montana\")]\n",
    "dfmt=pd.concat([df1, df2])\n",
    "dfmt['Area text']=\"MT\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NE\")]\n",
    "df2=df[df['Area text'].str.contains(\"Nebraska\")]\n",
    "dfne=pd.concat([df1, df2])\n",
    "dfne['Area text']=\"NE\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NV\")]\n",
    "df2=df[df['Area text'].str.contains(\"Nevada\")]\n",
    "dfnv=pd.concat([df1, df2])\n",
    "dfnv['Area text']=\"NV\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NH\")]\n",
    "df2=df[df['Area text'].str.contains(\"New Hampshire\")]\n",
    "dfnh=pd.concat([df1, df2])\n",
    "dfnh['Area text']=\"NH\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NJ\")]\n",
    "df2=df[df['Area text'].str.contains(\"New Jersey\")]\n",
    "dfnj=pd.concat([df1, df2])\n",
    "dfnj['Area text']=\"NJ\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NM\")]\n",
    "df2=df[df['Area text'].str.contains(\"New Mexico\")]\n",
    "dfnm=pd.concat([df1, df2])\n",
    "dfnm['Area text']=\"NM\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NY\")]\n",
    "df2=df[df['Area text'].str.contains(\"New York\")]\n",
    "df3=df2[df2['Area text']!='New York-Newark-Jersey City, NY-NJ-PA']\n",
    "dfny=pd.concat([df1, df3])\n",
    "dfny['Area text']=\"NY\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NC\")]\n",
    "df2=df[df['Area text'].str.contains(\"North Carolina\")]\n",
    "dfnc=pd.concat([df1, df2])\n",
    "dfnc['Area text']=\"NC\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", ND\")]\n",
    "df2=df[df['Area text'].str.contains(\"North Dakota\")]\n",
    "dfnd=pd.concat([df1, df2])\n",
    "dfnd['Area text']=\"ND\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", OH\")]\n",
    "df2=df[df['Area text'].str.contains(\"Ohio\")]\n",
    "dfoh=pd.concat([df1, df2])\n",
    "dfoh['Area text']=\"OH\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", OK\")]\n",
    "df2=df[df['Area text'].str.contains(\"Oklahoma\")]\n",
    "df3=df2[df2['Area text']!='Oklahoma City, OK']\n",
    "dfok=pd.concat([df1, df3])\n",
    "dfok['Area text']=\"OK\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", OR\")]\n",
    "df2=df[df['Area text'].str.contains(\"Oregon\")]\n",
    "dfor=pd.concat([df1, df2])\n",
    "dfor['Area text']=\"OR\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", PA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Pennsylvania\")]\n",
    "dfpa=pd.concat([df1, df2])\n",
    "dfpa['Area text']=\"PA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", RI\")]\n",
    "df2=df[df['Area text'].str.contains(\"Rhode Island\")]\n",
    "dfri=pd.concat([df1, df2])\n",
    "dfri['Area text']=\"RI\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", SC\")]\n",
    "df2=df[df['Area text'].str.contains(\"South Carolina\")]\n",
    "dfsc=pd.concat([df1, df2])\n",
    "dfsc['Area text']=\"SC\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", SD\")]\n",
    "df2=df[df['Area text'].str.contains(\"South Dakota\")]\n",
    "dfsd=pd.concat([df1, df2])\n",
    "dfsd['Area text']=\"SD\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", TN\")]\n",
    "df2=df[df['Area text'].str.contains(\"Tennessee\")]\n",
    "dftn=pd.concat([df1, df2])\n",
    "dftn['Area text']=\"TN\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", TX\")]\n",
    "df2=df[df['Area text'].str.contains(\"Texas\")]\n",
    "dftx=pd.concat([df1, df2])\n",
    "dftx['Area text']=\"TX\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", UT\")]\n",
    "df2=df[df['Area text'].str.contains(\"Utah\")]\n",
    "dfut=pd.concat([df1, df2])\n",
    "dfut['Area text']=\"UT\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", VT\")]\n",
    "df2=df[df['Area text'].str.contains(\"Vermont\")]\n",
    "dfvt=pd.concat([df1, df2])\n",
    "dfvt['Area text']=\"VT\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", VA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Virginia\")]\n",
    "df3=df2[df2['Area text']!='Virginia Beach-Norfolk-Newport News, VA-NC']\n",
    "df4=df3[df3['Area text']!='Northern West Virginia nonmetropolitan area']\n",
    "df5=df4[df4['Area text']!='Southern West Virginia nonmetropolitan area']\n",
    "df6=df5[df5['Area text']!='West Virginia']\n",
    "dfva=pd.concat([df1, df6])\n",
    "dfva['Area text']=\"VA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", WA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Washington\")]\n",
    "dfwa=pd.concat([df1, df2])\n",
    "dfwa['Area text']=\"WA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", WV\")]\n",
    "df2=df[df['Area text'].str.contains(\"West Virginia\")]\n",
    "dfwv=pd.concat([df1, df2])\n",
    "dfwv['Area text']=\"WV\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", WI\")]\n",
    "df2=df[df['Area text'].str.contains(\"Wisconsin\")]\n",
    "dfwi=pd.concat([df1, df2])\n",
    "dfwi['Area text']=\"WI\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", WY\")]\n",
    "df2=df[df['Area text'].str.contains(\"Wyoming\")]\n",
    "df3=df2[df2['Area text']!='Grand Rapids-Wyoming, MI']\n",
    "dfwy=pd.concat([df1, df3])\n",
    "dfwy['Area text']=\"WY\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774dcf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [dfal, dfak, dfaz, dfar, dfca, dfco, dfct, dfde, dffl, dfga, dfhi, dfid, dfil, dfin, dfia, dfks, dfky, dfla, dfme, dfmd, dfma, dfmi, dfmn, dfms, dfmo, dfmt, dfne, dfnv, dfnh, dfnj, dfnm, dfny, dfnc, dfnd, dfoh, dfok, dfor, dfpa, dfri, dfsc, dfsd, dftn, dftx, dfut, dfvt, dfva, dfwa, dfwv, dfwi, dfwy] \n",
    "for z in states: \n",
    "    z['Code'] = z['Area text'] + z['Job Category']\n",
    "test = dfal['Code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [dfal, dfak, dfaz, dfar, dfca, dfco, dfct, dfde, dffl, dfga, dfhi, dfid, dfil, dfin, dfia, dfks, dfky, dfla, dfme, dfmd, dfma, dfmi, dfmn, dfms, dfmo, dfmt, dfne, dfnv, dfnh, dfnj, dfnm, dfny, dfnc, dfnd, dfoh, dfok, dfor, dfpa, dfri, dfsc, dfsd, dftn, dftx, dfut, dfvt, dfva, dfwa, dfwv, dfwi, dfwy]    \n",
    "# geojsonpath = '../resources/geojsons/states.geojson'\n",
    "# geojson1 = pd.read_json(geojsonpath)\n",
    "newtest = pygeoj.load('../resources/geojsons/test.geojson')\n",
    "\n",
    "# for x in states:\n",
    "#     print(x)\n",
    "#     teststate = x.groupby(['Occupation text'])  \n",
    "#     teststate2 = teststate[\"Job characteristic code\"].count().reset_index().sort_values('Occupation text').set_index('Occupation text')\n",
    "#     testdict = teststate2.to_dict()\n",
    "#     index = states.index(x)+1\n",
    "#     print(index)\n",
    "#     newtest[index].properties = testdict['Job characteristic code']\n",
    "#     newtest[index].properties['jobs'] = testdict\n",
    "\n",
    "def Merge(a, b):\n",
    "    return(b.update(a))\n",
    "counter=0\n",
    "added=[]\n",
    "\n",
    "for x in states:\n",
    "    teststate = x.groupby(['Job Category'])\n",
    "    teststate2 = teststate[\"Code\"].count().reset_index().sort_values('Job Category').set_index('Job Category')\n",
    "    testdict = teststate2.to_dict()\n",
    "    added.append(testdict)\n",
    "# #     print(testdict)\n",
    "#     newtest[y].properties=testdict['Job characteristic code']\n",
    "#     newtest[y].properties['jobs']=testdict\n",
    "#     y=+1\n",
    "\n",
    "for y in newtest:\n",
    "        \n",
    "        Merge(added[counter]['Code'], y.properties)\n",
    "        y.properties['jobs']=added[counter]\n",
    "        if (counter<50):\n",
    "            counter+=1\n",
    "        \n",
    "        \n",
    "\n",
    "newtest.save(\"../resources/geojsons/datachoropleth.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b29699c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Category</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company Location</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4347</th>\n",
       "      <td>Big Data Software Engineer</td>\n",
       "      <td>Senior Software Engineer - Big Data - Ranking ...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>$132,000 - $192,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>Big Data Software Engineer</td>\n",
       "      <td>Software Engineer, Deep Learning Infrastructur...</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>Estimated $121K â€“ $154K a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>Big Data Software Engineer</td>\n",
       "      <td>Software Engineer, Notifications Experience</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Cupertino, CA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017</th>\n",
       "      <td>Big Data Software Engineer</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>Estimated $77.8K â€“ $98.4K a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>Big Data Software Engineer</td>\n",
       "      <td>LEAD SOFTWARE ENGINEER, CASINO (WEB)</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Estimated $133K â€“ $168K a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15208</th>\n",
       "      <td>Statistician</td>\n",
       "      <td>Statistician, Quality Analytics</td>\n",
       "      <td>Invitae</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>From $55,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15209</th>\n",
       "      <td>Statistician</td>\n",
       "      <td>SAS Programmer</td>\n",
       "      <td>NoyMed CRO</td>\n",
       "      <td>Remote</td>\n",
       "      <td>$36,000 - $55,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15210</th>\n",
       "      <td>Statistician</td>\n",
       "      <td>Research Scientist I</td>\n",
       "      <td>Medical College of Wisconsin</td>\n",
       "      <td>Milwaukee, WI</td>\n",
       "      <td>Estimated $57.3K â€“ $72.5K a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15204</th>\n",
       "      <td>Statistician</td>\n",
       "      <td>Senior Statistician</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Alameda, CA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15550</th>\n",
       "      <td>Statistician</td>\n",
       "      <td>Senior Biostatistician</td>\n",
       "      <td>Labcorp</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21245 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Job Category  \\\n",
       "4347   Big Data Software Engineer   \n",
       "5019   Big Data Software Engineer   \n",
       "5018   Big Data Software Engineer   \n",
       "5017   Big Data Software Engineer   \n",
       "5016   Big Data Software Engineer   \n",
       "...                           ...   \n",
       "15208                Statistician   \n",
       "15209                Statistician   \n",
       "15210                Statistician   \n",
       "15204                Statistician   \n",
       "15550                Statistician   \n",
       "\n",
       "                                               Job Title  \\\n",
       "4347   Senior Software Engineer - Big Data - Ranking ...   \n",
       "5019   Software Engineer, Deep Learning Infrastructur...   \n",
       "5018         Software Engineer, Notifications Experience   \n",
       "5017                                   Software Engineer   \n",
       "5016                LEAD SOFTWARE ENGINEER, CASINO (WEB)   \n",
       "...                                                  ...   \n",
       "15208                    Statistician, Quality Analytics   \n",
       "15209                                     SAS Programmer   \n",
       "15210                               Research Scientist I   \n",
       "15204                                Senior Statistician   \n",
       "15550                             Senior Biostatistician   \n",
       "\n",
       "                       Company Name Company Location  \\\n",
       "4347                         Indeed       Austin, TX   \n",
       "5019                          Tesla    Palo Alto, CA   \n",
       "5018                          Apple    Cupertino, CA   \n",
       "5017                      Microsoft     Honolulu, HI   \n",
       "5016                     DraftKings       Boston, MA   \n",
       "...                             ...              ...   \n",
       "15208                       Invitae      Boulder, CO   \n",
       "15209                    NoyMed CRO           Remote   \n",
       "15210  Medical College of Wisconsin    Milwaukee, WI   \n",
       "15204           Abbott Laboratories      Alameda, CA   \n",
       "15550                       Labcorp       Durham, NC   \n",
       "\n",
       "                                   Salary  \n",
       "4347           $132,000 - $192,000 a year  \n",
       "5019     Estimated $121K â€“ $154K a year  \n",
       "5018                                  NaN  \n",
       "5017   Estimated $77.8K â€“ $98.4K a year  \n",
       "5016     Estimated $133K â€“ $168K a year  \n",
       "...                                   ...  \n",
       "15208                 From $55,000 a year  \n",
       "15209            $36,000 - $55,000 a year  \n",
       "15210  Estimated $57.3K â€“ $72.5K a year  \n",
       "15204                                 NaN  \n",
       "15550                                 NaN  \n",
       "\n",
       "[21245 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"https://mw-project-4.s3.us-west-1.amazonaws.com/mw_scraped_indeedjobs.csv\"\n",
    "bigcsv = pd.read_csv(filepath)\n",
    "alldf = bigcsv.sort_values('Job Category')\n",
    "alldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "661f648f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amazon.com Services LLC                549\n",
       "Amazon Web Services, Inc.              429\n",
       "Meta                                   377\n",
       "WarnerMedia                            368\n",
       "Microsoft                              340\n",
       "                                      ... \n",
       "LOJISTIC                                 1\n",
       "Fairfax County Government                1\n",
       "Silex Data Solutions                     1\n",
       "Beam Inc.                                1\n",
       "PrimeSource Building Products, Inc.      1\n",
       "Name: Company Name, Length: 6378, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldf['Company Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6126f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c721478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef86d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e481b34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b5a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6539b53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c32da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d1a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8920ed56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22934dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3fe70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "535179d6",
   "metadata": {},
   "source": [
    "# SCRAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48adf6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da29f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_url = \"https://www.bls.gov/oes/current/oes_nat.htm\"\n",
    "tablehtml = pd.read_html(table_url)\n",
    "tableraw = tablehtml[0]\n",
    "tableraw = tableraw.drop([0, 1041])\n",
    "tableraw = tableraw.rename(columns = {\"Occupation title (click on the occupation title to view its profile)\": \"Occupation\", 'Employment': 'Number_of_Jobs_Listed','Employment per 1,000 jobs': 'Job_Frequency', 'Annual mean wage': 'Salary'})\n",
    "\n",
    "#table with grouped categories\n",
    "maincategories = tableraw[tableraw['Occupation code'].str[3].isin(['0'])].reset_index(drop = True)\n",
    "\n",
    "\n",
    "#cleaned up full table\n",
    "cleanedtable = tableraw.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "# cleanedtable\n",
    "maincategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c961ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "management_occupations = tableraw[tableraw['Occupation code'].str.contains('11-')].reset_index(drop = True)\n",
    "management_occupations = management_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "business_occupations = tableraw[tableraw['Occupation code'].str.contains('13-')].reset_index(drop = True)\n",
    "business_occupations = business_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "computer_occupations = tableraw[tableraw['Occupation code'].str.contains('15-')].reset_index(drop = True)\n",
    "computer_occupations = computer_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "engineering_occupations = tableraw[tableraw['Occupation code'].str.contains('17-')].reset_index(drop = True)\n",
    "engineering_occupations = engineering_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "science_occupations = tableraw[tableraw['Occupation code'].str.contains('19-')].reset_index(drop = True)\n",
    "science_occupations = science_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "social_occupations = tableraw[tableraw['Occupation code'].str.contains('21-')].reset_index(drop = True)\n",
    "social_occupations = social_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "legal_occupations = tableraw[tableraw['Occupation code'].str.contains('23-')].reset_index(drop = True)\n",
    "legal_occupations = legal_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "education_occupations = tableraw[tableraw['Occupation code'].str.contains('25-')].reset_index(drop = True)\n",
    "education_occupations = education_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "arts_occupations = tableraw[tableraw['Occupation code'].str.contains('27-')].reset_index(drop = True)\n",
    "arts_occupations = arts_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "healthcare_occupations = tableraw[tableraw['Occupation code'].str.contains('29-')].reset_index(drop = True)\n",
    "healthcare_occupations = healthcare_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "healthcaresup_occupations = tableraw[tableraw['Occupation code'].str.contains('31-')].reset_index(drop = True)\n",
    "healthcaresup_occupations = healthcaresup_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "protective_occupations = tableraw[tableraw['Occupation code'].str.contains('33-')].reset_index(drop = True)\n",
    "protective_occupations = protective_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "food_occupations = tableraw[tableraw['Occupation code'].str.contains('35-')].reset_index(drop = True)\n",
    "food_occupations = food_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "building_occupations = tableraw[tableraw['Occupation code'].str.contains('37-')].reset_index(drop = True)\n",
    "building_occupations = building_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "personalcare_occupations = tableraw[tableraw['Occupation code'].str.contains('39-')].reset_index(drop = True)\n",
    "personalcare_occupations = personalcare_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "sales_occupations = tableraw[tableraw['Occupation code'].str.contains('41-')].reset_index(drop = True)\n",
    "sales_occupations = sales_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "office_occupations = tableraw[tableraw['Occupation code'].str.contains('43-')].reset_index(drop = True)\n",
    "office_occupations = office_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "farming_occupations = tableraw[tableraw['Occupation code'].str.contains('45-')].reset_index(drop = True)\n",
    "farming_occupations = farming_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "construction_occupations = tableraw[tableraw['Occupation code'].str.contains('47-')].reset_index(drop = True)\n",
    "construction_occupations = construction_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "maintenance_occupations = tableraw[tableraw['Occupation code'].str.contains('49-')].reset_index(drop = True)\n",
    "maintenance_occupations = maintenance_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "production_occupations = tableraw[tableraw['Occupation code'].str.contains('51-')].reset_index(drop = True)\n",
    "production_occupations = production_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "transportation_occupations = tableraw[tableraw['Occupation code'].str.contains('53-')].reset_index(drop = True)\n",
    "transportation_occupations = transportation_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "# test = transportation_occupations.to_dict('records')\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ae0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvpath = \"../resources/choroplethedit.csv\"\n",
    "wagecsv = pd.read_csv(csvpath)\n",
    "softwarecsv = wagecsv[wagecsv['Occupation text'].str.contains(\"Software\")]\n",
    "computercsv = wagecsv[wagecsv['Occupation text'].str.contains(\"Computer\")]\n",
    "newdf = pd.concat([computercsv, softwarecsv])\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94188e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Database Admin', 'Big Data Software Engineer', 'Quantitative Analyst', 'IT Systems Analyst', \n",
    "             'Data Analyst', 'Business Intelligence Analyst', 'Data Architect', 'Business Systems Analyst', \n",
    "             'Machine Learning Engineer', 'Data Engineer', 'Data Scientist', 'Machine Learning Scientist', \n",
    "             'Business Intelligence Developer', 'Logistics Analyst', 'Marketing Analyst', 'Data Warehouse Manager', \n",
    "             'Statistician', 'Data Storyteller', 'Database Administrator', 'Database Manager', 'Data Modeler']\n",
    "jobnumbers = [i for i in range(21)]\n",
    "statenumbers = [i for i in range(50)]\n",
    "# dfca['Code'] = dfca['Area text'] + dfca['Job Category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1abf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonational = newdf.loc[newdf['Area text'] != 'National']\n",
    "# df=nonational.sort_values('Occupation text')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0131c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_list = nonational['Occupation text'].unique()\n",
    "# for x in occupation_list:\n",
    "    \n",
    "#     print(x)\n",
    "len(occupation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgroup=bigboi.groupby(['Occupation text','Area text'])\n",
    "# bgroup[\"Job characteristic code\"].count().reset_index().to_csv(\"../resources/IgotchuAndrew_sj.csv\")\n",
    "bggroup2 = bgroup[\"Job characteristic code\"].count().reset_index().sort_values('Occupation text')\n",
    "bggroup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6608e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "states = [dfal, dfak, dfaz, dfar, dfca, dfco, dfct, dfde, dfdc, dffl, dfga, dfhi, dfid, dfil, dfin, dfia, dfks, dfky, dfla, dfme, dfmd, dfma, dfmi, dfmn, dfms, dfmo, dfmt, dfne, dfnv, dfnh, dfnj, dfnm, dfny, dfnc, dfnd, dfoh, dfok, dfor, dfpa, dfri, dfsc, dfsd, dftn, dftx, dfut, dfvt, dfva, dfwa, dfwv, dfwi, dfwy]    \n",
    "# teststate = dfal.groupby(['Occupation text'])  \n",
    "# teststate2 = teststate[\"Job characteristic code\"].count().reset_index().sort_values('Occupation text').set_index('Occupation text')\n",
    "# testdict = teststate2.to_dict()\n",
    "# testdict\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0816dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alabama = 0\n",
    "# Alaska = 0\n",
    "# Arizona = 0\n",
    "# Arkansas = 0\n",
    "# California = 0\n",
    "# Colorado = 0\n",
    "# Connecticut = 0\n",
    "# Delaware = 0\n",
    "# DistrictColumbia = 0\n",
    "# Florida = 0\n",
    "# Georgia = 0\n",
    "# Hawaii = 0\n",
    "# Idaho = 0\n",
    "# Illinois = 0\n",
    "# Indiana = 0\n",
    "# Iowa =  0\n",
    "# Kansas = 0\n",
    "# Kentucky = 0\n",
    "# Louisiana = 0\n",
    "# Maine = 0\n",
    "# Maryland = 0\n",
    "# Massachusetts = 0\n",
    "# Michigan = 0\n",
    "# Minnesota = 0\n",
    "# Mississippi = 0\n",
    "# Missouri = 0\n",
    "# Montana = 0\n",
    "# Nebraska = 0\n",
    "# Nevada = 0\n",
    "# NewHampshire = 0\n",
    "# NewJersey = 0\n",
    "# NewMexico = 0\n",
    "# NewYork = 0\n",
    "# NorthCarolina = 0\n",
    "# NorthDakota = 0\n",
    "# Ohio = 0\n",
    "# Oklahoma = 0\n",
    "# Oregon = 0\n",
    "# Pennsylvania = 0\n",
    "# RhodeIsland = 0\n",
    "# SouthCarolina = 0\n",
    "# SouthDakota = 0\n",
    "# Tennessee = 0\n",
    "# Texas = 0\n",
    "# Utah = 0\n",
    "# Vermont = 0\n",
    "# Virginia = 0\n",
    "# Washington = 0\n",
    "# WestVirginia = 0\n",
    "# Wisconsin = 0\n",
    "# Wyoming = 0"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0507ca4863d74825e19143f64061a0d98fde3c42611721bd9ba5ee5b8cfcb010"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
