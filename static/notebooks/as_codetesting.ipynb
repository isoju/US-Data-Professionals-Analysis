{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f787dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import prettytable\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pygeoj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "367a632e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database Admin                     1536\n",
       "Big Data Software Engineer         1201\n",
       "Quantitative Analyst               1150\n",
       "IT Systems Analyst                 1082\n",
       "Data Analyst                       1076\n",
       "Business Intelligence Analyst      1074\n",
       "Data Architect                     1068\n",
       "Business Systems Analyst           1047\n",
       "Machine Learning Engineer          1043\n",
       "Data Engineer                      1040\n",
       "Data Scientist                     1031\n",
       "Machine Learning Scientist         1031\n",
       "Business Intelligence Developer    1026\n",
       "Logistics Analyst                  1024\n",
       "Marketing Analyst                  1023\n",
       "Data Warehouse Manager             1021\n",
       "Statistician                       1017\n",
       "Data Storyteller                   1016\n",
       "Database Administrator              859\n",
       "Database Manager                    442\n",
       "Data Modeler                        438\n",
       "Name: Job Category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"https://mw-project-4.s3.us-west-1.amazonaws.com/mw_scraped_indeedjobs.csv\"\n",
    "bigcsv = pd.read_csv(filepath)\n",
    "alldf = bigcsv.sort_values('Job Category')\n",
    "df = alldf.rename(columns = {'Company Location': 'Area text'})\n",
    "df['Job Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a22bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[df['Area text'].str.contains(\", CA\")]\n",
    "df2=df[df['Area text'].str.contains(\"California\")]\n",
    "df3=df2[df2['Area text']!='California-Lexington Park, MD']\n",
    "dfca=pd.concat([df1, df3])\n",
    "dfca['Area text']=\"CA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", AL\")]\n",
    "df2=df[df['Area text'].str.contains(\"Alabama\")]\n",
    "dfal=pd.concat([df1, df2])\n",
    "dfal['Area text']=\"AL\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", AK\")]\n",
    "df2=df[df['Area text'].str.contains(\"Alaska\")]\n",
    "dfak=pd.concat([df1, df2])\n",
    "dfak['Area text']=\"AK\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", AZ\")]\n",
    "df2=df[df['Area text'].str.contains(\"Arizona\")]\n",
    "dfaz=pd.concat([df1, df2])\n",
    "dfaz['Area text']=\"AZ\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", AR\")]\n",
    "df2=df[df['Area text'].str.contains(\"Arkansas\")]\n",
    "dfar=pd.concat([df1, df2])\n",
    "dfar['Area text']=\"AR\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", CO\")]\n",
    "df2=df[df['Area text'].str.contains(\"Colorado\")]\n",
    "dfco=pd.concat([df1, df2])\n",
    "dfco['Area text']=\"CO\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", CT\")]\n",
    "df2=df[df['Area text'].str.contains(\"Connecticut\")]\n",
    "dfct=pd.concat([df1, df2])\n",
    "dfct['Area text']=\"CT\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", DE\")]\n",
    "df2=df[df['Area text'].str.contains(\"Delaware\")]\n",
    "dfde=pd.concat([df1, df2])\n",
    "dfde['Area text']=\"DE\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "# dfdc=df[df['Area text'].str.contains(\"District of Columbia\")]\n",
    "# dfdc['Area text']=\"DC\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", FL\")]\n",
    "df2=df[df['Area text'].str.contains(\"Florida\")]\n",
    "dffl=pd.concat([df1, df2])\n",
    "dffl['Area text']=\"FL\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", GA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Georgia\")]\n",
    "dfga=pd.concat([df1, df2])\n",
    "dfga['Area text']=\"GA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", HI\")]\n",
    "df2=df[df['Area text'].str.contains(\"Hawaii\")]\n",
    "dfhi=pd.concat([df1, df2])\n",
    "dfhi['Area text']=\"HI\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", ID\")]\n",
    "df2=df[df['Area text'].str.contains(\"Idaho\")]\n",
    "dfid=pd.concat([df1, df2])\n",
    "dfid['Area text']=\"ID\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", IL\")]\n",
    "df2=df[df['Area text'].str.contains(\"Illinois\")]\n",
    "dfil=pd.concat([df1, df2])\n",
    "dfil['Area text']=\"IL\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", IN\")]\n",
    "df2=df[df['Area text'].str.contains(\"Indiana\")]\n",
    "df3=df2[df2['Area text']!='Indianapolis-Carmel-Anderson, IN']\n",
    "dfin=pd.concat([df1, df3])\n",
    "dfin['Area text']=\"IN\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", IA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Iowa\")]\n",
    "df3=df2[df2['Area text']!=\"Iowa City, IA\"]\n",
    "dfia=pd.concat([df1, df3])\n",
    "dfia['Area text']=\"IA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", KS\")]\n",
    "df2=df[df['Area text'].str.contains(\"Kansas\")]\n",
    "dfks=pd.concat([df1, df2])\n",
    "dfks['Area text']=\"KS\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", KY\")]\n",
    "df2=df[df['Area text'].str.contains(\"Kentucky\")]\n",
    "dfky=pd.concat([df1, df2])\n",
    "dfky['Area text']=\"KY\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", LA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Louisiana\")]\n",
    "dfla=pd.concat([df1, df2])\n",
    "dfla['Area text']=\"LA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", ME\")]\n",
    "df2=df[df['Area text'].str.contains(\"Maine\")]\n",
    "dfme=pd.concat([df1, df2])\n",
    "dfme['Area text']=\"ME\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MD\")]\n",
    "df2=df[df['Area text'].str.contains(\"Maryland\")]\n",
    "dfmd=pd.concat([df1, df2])\n",
    "dfmd['Area text']=\"MD\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Massachusetts\")]\n",
    "dfma=pd.concat([df1, df2])\n",
    "dfma['Area text']=\"MA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MI\")]\n",
    "df2=df[df['Area text'].str.contains(\"Michigan\")]\n",
    "df3=df2[df2['Area text']!='Michigan City-La Porte, IN']\n",
    "dfmi=pd.concat([df1, df3])\n",
    "dfmi['Area text']=\"MI\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MN\")]\n",
    "df2=df[df['Area text'].str.contains(\"Minnesota\")]\n",
    "dfmn=pd.concat([df1, df2])\n",
    "dfmn['Area text']=\"MN\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MS\")]\n",
    "df2=df[df['Area text'].str.contains(\"Mississippi\")]\n",
    "dfms=pd.concat([df1, df2])\n",
    "dfms['Area text']=\"MS\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MO\")]\n",
    "df2=df[df['Area text'].str.contains(\"Missouri\")]\n",
    "dfmo=pd.concat([df1, df2])\n",
    "dfmo['Area text']=\"MO\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", MT\")]\n",
    "df2=df[df['Area text'].str.contains(\"Montana\")]\n",
    "dfmt=pd.concat([df1, df2])\n",
    "dfmt['Area text']=\"MT\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NE\")]\n",
    "df2=df[df['Area text'].str.contains(\"Nebraska\")]\n",
    "dfne=pd.concat([df1, df2])\n",
    "dfne['Area text']=\"NE\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NV\")]\n",
    "df2=df[df['Area text'].str.contains(\"Nevada\")]\n",
    "dfnv=pd.concat([df1, df2])\n",
    "dfnv['Area text']=\"NV\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NH\")]\n",
    "df2=df[df['Area text'].str.contains(\"New Hampshire\")]\n",
    "dfnh=pd.concat([df1, df2])\n",
    "dfnh['Area text']=\"NH\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NJ\")]\n",
    "df2=df[df['Area text'].str.contains(\"New Jersey\")]\n",
    "dfnj=pd.concat([df1, df2])\n",
    "dfnj['Area text']=\"NJ\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NM\")]\n",
    "df2=df[df['Area text'].str.contains(\"New Mexico\")]\n",
    "dfnm=pd.concat([df1, df2])\n",
    "dfnm['Area text']=\"NM\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NY\")]\n",
    "df2=df[df['Area text'].str.contains(\"New York\")]\n",
    "df3=df2[df2['Area text']!='New York-Newark-Jersey City, NY-NJ-PA']\n",
    "dfny=pd.concat([df1, df3])\n",
    "dfny['Area text']=\"NY\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", NC\")]\n",
    "df2=df[df['Area text'].str.contains(\"North Carolina\")]\n",
    "dfnc=pd.concat([df1, df2])\n",
    "dfnc['Area text']=\"NC\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", ND\")]\n",
    "df2=df[df['Area text'].str.contains(\"North Dakota\")]\n",
    "dfnd=pd.concat([df1, df2])\n",
    "dfnd['Area text']=\"ND\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", OH\")]\n",
    "df2=df[df['Area text'].str.contains(\"Ohio\")]\n",
    "dfoh=pd.concat([df1, df2])\n",
    "dfoh['Area text']=\"OH\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", OK\")]\n",
    "df2=df[df['Area text'].str.contains(\"Oklahoma\")]\n",
    "df3=df2[df2['Area text']!='Oklahoma City, OK']\n",
    "dfok=pd.concat([df1, df3])\n",
    "dfok['Area text']=\"OK\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", OR\")]\n",
    "df2=df[df['Area text'].str.contains(\"Oregon\")]\n",
    "dfor=pd.concat([df1, df2])\n",
    "dfor['Area text']=\"OR\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", PA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Pennsylvania\")]\n",
    "dfpa=pd.concat([df1, df2])\n",
    "dfpa['Area text']=\"PA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", RI\")]\n",
    "df2=df[df['Area text'].str.contains(\"Rhode Island\")]\n",
    "dfri=pd.concat([df1, df2])\n",
    "dfri['Area text']=\"RI\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", SC\")]\n",
    "df2=df[df['Area text'].str.contains(\"South Carolina\")]\n",
    "dfsc=pd.concat([df1, df2])\n",
    "dfsc['Area text']=\"SC\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", SD\")]\n",
    "df2=df[df['Area text'].str.contains(\"South Dakota\")]\n",
    "dfsd=pd.concat([df1, df2])\n",
    "dfsd['Area text']=\"SD\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", TN\")]\n",
    "df2=df[df['Area text'].str.contains(\"Tennessee\")]\n",
    "dftn=pd.concat([df1, df2])\n",
    "dftn['Area text']=\"TN\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", TX\")]\n",
    "df2=df[df['Area text'].str.contains(\"Texas\")]\n",
    "dftx=pd.concat([df1, df2])\n",
    "dftx['Area text']=\"TX\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", UT\")]\n",
    "df2=df[df['Area text'].str.contains(\"Utah\")]\n",
    "dfut=pd.concat([df1, df2])\n",
    "dfut['Area text']=\"UT\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", VT\")]\n",
    "df2=df[df['Area text'].str.contains(\"Vermont\")]\n",
    "dfvt=pd.concat([df1, df2])\n",
    "dfvt['Area text']=\"VT\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", VA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Virginia\")]\n",
    "df3=df2[df2['Area text']!='Virginia Beach-Norfolk-Newport News, VA-NC']\n",
    "df4=df3[df3['Area text']!='Northern West Virginia nonmetropolitan area']\n",
    "df5=df4[df4['Area text']!='Southern West Virginia nonmetropolitan area']\n",
    "df6=df5[df5['Area text']!='West Virginia']\n",
    "dfva=pd.concat([df1, df6])\n",
    "dfva['Area text']=\"VA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", WA\")]\n",
    "df2=df[df['Area text'].str.contains(\"Washington\")]\n",
    "dfwa=pd.concat([df1, df2])\n",
    "dfwa['Area text']=\"WA\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", WV\")]\n",
    "df2=df[df['Area text'].str.contains(\"West Virginia\")]\n",
    "dfwv=pd.concat([df1, df2])\n",
    "dfwv['Area text']=\"WV\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", WI\")]\n",
    "df2=df[df['Area text'].str.contains(\"Wisconsin\")]\n",
    "dfwi=pd.concat([df1, df2])\n",
    "dfwi['Area text']=\"WI\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()\n",
    "\n",
    "df1=df[df['Area text'].str.contains(\", WY\")]\n",
    "df2=df[df['Area text'].str.contains(\"Wyoming\")]\n",
    "df3=df2[df2['Area text']!='Grand Rapids-Wyoming, MI']\n",
    "dfwy=pd.concat([df1, df3])\n",
    "dfwy['Area text']=\"WY\"\n",
    "# dfca['Occupation text'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774dcf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [dfal, dfak, dfaz, dfar, dfca, dfco, dfct, dfde, dffl, dfga, dfhi, dfid, dfil, dfin, dfia, dfks, dfky, dfla, dfme, dfmd, dfma, dfmi, dfmn, dfms, dfmo, dfmt, dfne, dfnv, dfnh, dfnj, dfnm, dfny, dfnc, dfnd, dfoh, dfok, dfor, dfpa, dfri, dfsc, dfsd, dftn, dftx, dfut, dfvt, dfva, dfwa, dfwv, dfwi, dfwy] \n",
    "for z in states: \n",
    "    z['Code'] = z['Area text'] + z['Job Category']\n",
    "test = dfal['Code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [dfal, dfak, dfaz, dfar, dfca, dfco, dfct, dfde, dffl, dfga, dfhi, dfid, dfil, dfin, dfia, dfks, dfky, dfla, dfme, dfmd, dfma, dfmi, dfmn, dfms, dfmo, dfmt, dfne, dfnv, dfnh, dfnj, dfnm, dfny, dfnc, dfnd, dfoh, dfok, dfor, dfpa, dfri, dfsc, dfsd, dftn, dftx, dfut, dfvt, dfva, dfwa, dfwv, dfwi, dfwy]    \n",
    "# geojsonpath = '../resources/geojsons/states.geojson'\n",
    "# geojson1 = pd.read_json(geojsonpath)\n",
    "newtest = pygeoj.load('../resources/geojsons/test.geojson')\n",
    "\n",
    "# for x in states:\n",
    "#     print(x)\n",
    "#     teststate = x.groupby(['Occupation text'])  \n",
    "#     teststate2 = teststate[\"Job characteristic code\"].count().reset_index().sort_values('Occupation text').set_index('Occupation text')\n",
    "#     testdict = teststate2.to_dict()\n",
    "#     index = states.index(x)+1\n",
    "#     print(index)\n",
    "#     newtest[index].properties = testdict['Job characteristic code']\n",
    "#     newtest[index].properties['jobs'] = testdict\n",
    "\n",
    "def Merge(a, b):\n",
    "    return(b.update(a))\n",
    "counter=0\n",
    "added=[]\n",
    "\n",
    "for x in states:\n",
    "    teststate = x.groupby(['Job Category'])\n",
    "    teststate2 = teststate[\"Code\"].count().reset_index().sort_values('Job Category').set_index('Job Category')\n",
    "    testdict = teststate2.to_dict()\n",
    "    added.append(testdict)\n",
    "# #     print(testdict)\n",
    "#     newtest[y].properties=testdict['Job characteristic code']\n",
    "#     newtest[y].properties['jobs']=testdict\n",
    "#     y=+1\n",
    "\n",
    "for y in newtest:\n",
    "        \n",
    "        Merge(added[counter]['Code'], y.properties)\n",
    "        y.properties['jobs']=added[counter]\n",
    "        if (counter<50):\n",
    "            counter+=1\n",
    "        \n",
    "        \n",
    "\n",
    "newtest.save(\"../resources/geojsons/datachoropleth.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29699c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"https://mw-project-4.s3.us-west-1.amazonaws.com/mw_scraped_indeedjobs.csv\"\n",
    "bigcsv = pd.read_csv(filepath)\n",
    "alldf = bigcsv.sort_values('Job Category')\n",
    "alldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf['Company Name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c84d4",
   "metadata": {},
   "source": [
    "# WEBSCRAPING GLASSDOOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c721478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1ef86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(keyword, num_jobs, verbose):\n",
    "    '''Gathers jobs as a dataframe, scraped from Glassdoor'''\n",
    "    # Initializing the webdriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # Uncomment the line below if you'd like to scrape without a new Chrome window every time.\n",
    "    # options.add_argument('headless')\n",
    "    # Change the path to where chromedriver is in your home folder.\n",
    "    driver = webdriver.Chrome(executable_path=ChromeDriverManager().install(), options=options)\n",
    "    driver.set_window_size(1120, 1000)\n",
    "    url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=' + keyword + '&locT=C&locId=1150505&jobType=all&fromAge=-1&minSalary=0&includeNoSalaryJobs=true&radius=100&cityId=-1&minRating=0.0&industryId=-1&sgocId=-1&seniorityType=all&companyId=-1&employerSizes=0&applicationType=0&remoteWorkType=0'    \n",
    "    driver.get(url)\n",
    "    global jobs\n",
    "    jobs = []\n",
    "    # Let the page load. Change this number based on your internet speed.\n",
    "    # Or, wait until the webpage is loaded, instead of hardcoding it.\n",
    "    time.sleep(5)\n",
    "    # Click on the first job & Test for the \"Sign Up\" prompt and get rid of it.\n",
    "    driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/ul/li[1]\").click()\n",
    "    time.sleep(1)\n",
    "    # Clicking on the Close X button to close the \"Sign Up\" prompt.\n",
    "    driver.find_element_by_xpath('//*[@id=\"JAModal\"]/div/div[2]/span').click()  \n",
    "    time.sleep(5)\n",
    "    # Clicking on the \"Search\" button to search for the job postings based on keywords entered.\n",
    "    driver.find_element_by_xpath('//*[@id=\"scBar\"]/div/button/span').click()\n",
    "    time.sleep(10)\n",
    "    while len(jobs) < num_jobs:\n",
    "        # Going through each job in this page\n",
    "        job_buttons = driver.find_elements_by_xpath(\"//*[@id='MainCol']/div[1]/ul/li\")\n",
    "        for job_button in job_buttons:  \n",
    "            print(\"Progress: {}\".format(\"\" + str(len(jobs)) + \"/\" + str(num_jobs)))\n",
    "            if len(jobs) >= num_jobs:\n",
    "                # When the number of jobs collected has reached the number we set.\n",
    "                break\n",
    "            job_button.click()  \n",
    "            time.sleep(5)\n",
    "            collected_successfully = False\n",
    "            while not collected_successfully:\n",
    "                try:\n",
    "                    time.sleep(5)\n",
    "                    company_name = driver.find_element_by_xpath('//*[@id=\"JDCol\"]/div/article/div/div[1]/div/div/div[1]/div[3]/div[1]/div[1]').text\n",
    "                    location = driver.find_element_by_xpath('//*[@id=\"JDCol\"]/div/article/div/div[1]/div/div/div[1]/div[3]/div[1]/div[3]').text\n",
    "                    job_title = driver.find_element_by_xpath('//*[@id=\"JDCol\"]/div/article/div/div[1]/div/div/div[1]/div[3]/div[1]/div[2]').text\n",
    "                    job_description = driver.find_element_by_xpath('//div[@class=\"jobDescriptionContent desc\"]').text\n",
    "                    collected_successfully = True\n",
    "                except:\n",
    "                    time.sleep(5)\n",
    "                    collected_successfully = True\n",
    "            try:\n",
    "                salary_estimate = driver.find_element_by_xpath('//*[@id=\"JDCol\"]/div/article/div/div[1]/div/div/div[1]/div[3]/div[1]/div[4]/span').text\n",
    "            except NoSuchElementException:\n",
    "                salary_estimate = -1 # You need to set a \"not found value. It's important.\"\n",
    "            try:\n",
    "                rating = driver.find_element_by_xpath('//*[@id=\"JDCol\"]/div/article/div/div[1]/div/div/div[1]/div[3]/div[1]/div[1]/span').text\n",
    "            except NoSuchElementException:\n",
    "                rating = -1 # You need to set a \"not found value. It's important.\"\n",
    "            # Printing for debugging\n",
    "            if verbose:\n",
    "                print(\"Job Title: {}\".format(job_title))\n",
    "                print(\"Salary Estimate: {}\".format(salary_estimate))\n",
    "                print(\"Job Description: {}\".format(job_description))\n",
    "                print(\"Rating: {}\".format(rating))\n",
    "                print(\"Company Name: {}\".format(company_name))\n",
    "                print(\"Location: {}\".format(location))\n",
    "            # Going to the Company tab...\n",
    "            time.sleep(5)\n",
    "            try:\n",
    "                driver.find_element_by_xpath('//div[@data-item=\"tab\" and @data-tab-type=\"overview\"]').click()\n",
    "                time.sleep(5)\n",
    "                try:\n",
    "                    size = driver.find_element_by_xpath('//*[@id=\"EmpBasicInfo\"]/div[1]/div/div[1]/span[2]').text\n",
    "                except NoSuchElementException:\n",
    "                    size = -1\n",
    "                try:\n",
    "                    founded = driver.find_element_by_xpath('//*[@id=\"EmpBasicInfo\"]/div[1]/div/div[2]/span[2]').text\n",
    "                except NoSuchElementException:\n",
    "                    founded = -1\n",
    "                try:\n",
    "                    type_of_ownership = driver.find_element_by_xpath('//*[@id=\"EmpBasicInfo\"]/div[1]/div/div[3]/span[2]').text\n",
    "                except NoSuchElementException:\n",
    "                    type_of_ownership = -1\n",
    "                try:\n",
    "                    industry = driver.find_element_by_xpath('//*[@id=\"EmpBasicInfo\"]/div[1]/div/div[4]/span[2]').text\n",
    "                except NoSuchElementException:\n",
    "                    industry = -1\n",
    "                try:\n",
    "                    sector = driver.find_element_by_xpath('//*[@id=\"EmpBasicInfo\"]/div[1]/div/div[5]/span[2]').text\n",
    "                except NoSuchElementException:\n",
    "                    sector = -1\n",
    "                try:\n",
    "                    revenue = driver.find_element_by_xpath('//*[@id=\"EmpBasicInfo\"]/div[1]/div/div[6]/span[2]').text\n",
    "                except NoSuchElementException:\n",
    "                    revenue = -1\n",
    "            except NoSuchElementException:  # Rarely, some job postings do not have the \"Company\" tab.\n",
    "                size = -1\n",
    "                founded = -1\n",
    "                type_of_ownership = -1\n",
    "                industry = -1\n",
    "                sector = -1\n",
    "                revenue = -1\n",
    "            if verbose:\n",
    "                print(\"Size: {}\".format(size))\n",
    "                print(\"Founded: {}\".format(founded))\n",
    "                print(\"Type of Ownership: {}\".format(type_of_ownership))\n",
    "                print(\"Industry: {}\".format(industry))\n",
    "                print(\"Sector: {}\".format(sector))\n",
    "                print(\"Revenue: {}\".format(revenue))\n",
    "                print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "            jobs.append({\n",
    "            \"Job Title\" : job_title,\n",
    "            \"Salary Estimate\" : salary_estimate,\n",
    "            \"Job Description\" : job_description,\n",
    "            \"Rating\" : rating,\n",
    "            \"Company Name\" : company_name,\n",
    "            \"Location\" : location,\n",
    "            \"Size\" : size,\n",
    "            \"Founded\" : founded,\n",
    "            \"Type of ownership\" : type_of_ownership,\n",
    "            \"Industry\" : industry,\n",
    "            \"Sector\" : sector,\n",
    "            \"Revenue\" : revenue\n",
    "            })\n",
    "        # Clicking on the \"next page\" button\n",
    "        try:\n",
    "            driver.find_element_by_xpath('//*[@id=\"FooterPageNav\"]/div/ul/li[7]/a/span').click()\n",
    "            time.sleep(10)\n",
    "        except NoSuchElementException:\n",
    "            print(\"Scraping terminated before reaching target number of jobs. Needed {}, got {}.\".format(num_jobs, len(jobs)))\n",
    "            break\n",
    "    # This line converts the dictionary object into a pandas DataFrame.\n",
    "    return pd.DataFrame(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e481b34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 96.0.4664\n",
      "Get LATEST driver version for 96.0.4664\n",
      "Driver [C:\\Users\\Andrew\\.wdm\\drivers\\chromedriver\\win32\\96.0.4664.45\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0/1000\n",
      "Progress: 1/1000\n",
      "Progress: 2/1000\n",
      "Progress: 3/1000\n",
      "Progress: 4/1000\n",
      "Progress: 5/1000\n",
      "Progress: 6/1000\n",
      "Progress: 7/1000\n",
      "Progress: 8/1000\n",
      "Progress: 9/1000\n",
      "Progress: 10/1000\n",
      "Progress: 11/1000\n",
      "Progress: 12/1000\n",
      "Progress: 13/1000\n",
      "Progress: 14/1000\n",
      "Progress: 15/1000\n",
      "Progress: 16/1000\n",
      "Progress: 17/1000\n",
      "Progress: 18/1000\n",
      "Progress: 19/1000\n",
      "Progress: 20/1000\n",
      "Progress: 21/1000\n",
      "Progress: 22/1000\n",
      "Progress: 23/1000\n",
      "Progress: 24/1000\n",
      "Progress: 25/1000\n",
      "Progress: 26/1000\n",
      "Progress: 27/1000\n",
      "Progress: 28/1000\n",
      "Progress: 29/1000\n",
      "Scraping terminated before reaching target number of jobs. Needed 1000, got 30.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical Project Manager- Data Engineer</td>\n",
       "      <td>$67K - $129K (Glassdoor est.)</td>\n",
       "      <td>Overview:\\nCharlie’s Produce - Who We Are\\n\\nC...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Charlie's Produce\\n3.5</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>1978</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Wholesale</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>$500 million to $1 billion (USD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product Manager - Analytics</td>\n",
       "      <td>$79K - $143K (Glassdoor est.)</td>\n",
       "      <td>For nearly two decades, Zonar Systems has been...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Zonar Systems\\n3.2</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>201 to 500 Employees</td>\n",
       "      <td>2001</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Computer Hardware &amp; Software</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$100 to $500 million (USD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product Manager - Data Engineering</td>\n",
       "      <td>$58K - $125K (Glassdoor est.)</td>\n",
       "      <td>PeopleReady, a TrueBlue company (NYSE: TBI), i...</td>\n",
       "      <td>-1</td>\n",
       "      <td>PeopleReady</td>\n",
       "      <td>Tacoma, WA</td>\n",
       "      <td>5001 to 10000 Employees</td>\n",
       "      <td>1989</td>\n",
       "      <td>Subsidiary or Business Segment</td>\n",
       "      <td>Staffing &amp; Outsourcing</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>$50 to $100 million (USD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Integration Support Specialist for a market le...</td>\n",
       "      <td>Employer Provided Salary:$80K - $95K</td>\n",
       "      <td>Ticketing system experience\\nExcellent trouble...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Zest City</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIE Manager, AWS Data Exchange</td>\n",
       "      <td>-1</td>\n",
       "      <td>Bachelor’s degree in Business Analytics, Stati...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Amazon Web Services, Inc.\\n3.7</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1994</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0           Technical Project Manager- Data Engineer   \n",
       "1                        Product Manager - Analytics   \n",
       "2                 Product Manager - Data Engineering   \n",
       "3  Integration Support Specialist for a market le...   \n",
       "4                     BIE Manager, AWS Data Exchange   \n",
       "\n",
       "                        Salary Estimate  \\\n",
       "0         $67K - $129K (Glassdoor est.)   \n",
       "1         $79K - $143K (Glassdoor est.)   \n",
       "2         $58K - $125K (Glassdoor est.)   \n",
       "3  Employer Provided Salary:$80K - $95K   \n",
       "4                                    -1   \n",
       "\n",
       "                                     Job Description Rating  \\\n",
       "0  Overview:\\nCharlie’s Produce - Who We Are\\n\\nC...    3.5   \n",
       "1  For nearly two decades, Zonar Systems has been...    3.2   \n",
       "2  PeopleReady, a TrueBlue company (NYSE: TBI), i...     -1   \n",
       "3  Ticketing system experience\\nExcellent trouble...     -1   \n",
       "4  Bachelor’s degree in Business Analytics, Stati...    3.7   \n",
       "\n",
       "                     Company Name     Location                     Size  \\\n",
       "0          Charlie's Produce\\n3.5  Seattle, WA   1001 to 5000 Employees   \n",
       "1              Zonar Systems\\n3.2  Seattle, WA     201 to 500 Employees   \n",
       "2                     PeopleReady   Tacoma, WA  5001 to 10000 Employees   \n",
       "3                       Zest City  Seattle, WA                  Unknown   \n",
       "4  Amazon Web Services, Inc.\\n3.7  Seattle, WA         10000+ Employees   \n",
       "\n",
       "            Founded               Type of ownership  \\\n",
       "0              1978               Company - Private   \n",
       "1              2001               Company - Private   \n",
       "2              1989  Subsidiary or Business Segment   \n",
       "3  Company - Public        Unknown / Non-Applicable   \n",
       "4              1994                Company - Public   \n",
       "\n",
       "                       Industry                  Sector  \\\n",
       "0                     Wholesale       Business Services   \n",
       "1  Computer Hardware & Software  Information Technology   \n",
       "2        Staffing & Outsourcing       Business Services   \n",
       "3                            -1                      -1   \n",
       "4                      Internet  Information Technology   \n",
       "\n",
       "                            Revenue  \n",
       "0  $500 million to $1 billion (USD)  \n",
       "1        $100 to $500 million (USD)  \n",
       "2         $50 to $100 million (USD)  \n",
       "3                                -1  \n",
       "4                $10+ billion (USD)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datawarehousemanager = get_jobs(\"Data Warehouse Manager\", 1000, False)\n",
    "datawarehousemanager = pd.DataFrame(jobs)\n",
    "datawarehousemanager.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25b5a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical Project Manager- Data Engineer</td>\n",
       "      <td>$67K - $129K (Glassdoor est.)</td>\n",
       "      <td>Overview:\\nCharlie’s Produce - Who We Are\\n\\nC...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Charlie's Produce\\n3.5</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>1978</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Wholesale</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>$500 million to $1 billion (USD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product Manager - Analytics</td>\n",
       "      <td>$79K - $143K (Glassdoor est.)</td>\n",
       "      <td>For nearly two decades, Zonar Systems has been...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Zonar Systems\\n3.2</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>201 to 500 Employees</td>\n",
       "      <td>2001</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Computer Hardware &amp; Software</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$100 to $500 million (USD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product Manager - Data Engineering</td>\n",
       "      <td>$58K - $125K (Glassdoor est.)</td>\n",
       "      <td>PeopleReady, a TrueBlue company (NYSE: TBI), i...</td>\n",
       "      <td>-1</td>\n",
       "      <td>PeopleReady</td>\n",
       "      <td>Tacoma, WA</td>\n",
       "      <td>5001 to 10000 Employees</td>\n",
       "      <td>1989</td>\n",
       "      <td>Subsidiary or Business Segment</td>\n",
       "      <td>Staffing &amp; Outsourcing</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>$50 to $100 million (USD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Integration Support Specialist for a market le...</td>\n",
       "      <td>Employer Provided Salary:$80K - $95K</td>\n",
       "      <td>Ticketing system experience\\nExcellent trouble...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Zest City</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIE Manager, AWS Data Exchange</td>\n",
       "      <td>-1</td>\n",
       "      <td>Bachelor’s degree in Business Analytics, Stati...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Amazon Web Services, Inc.\\n3.7</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1994</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0           Technical Project Manager- Data Engineer   \n",
       "1                        Product Manager - Analytics   \n",
       "2                 Product Manager - Data Engineering   \n",
       "3  Integration Support Specialist for a market le...   \n",
       "4                     BIE Manager, AWS Data Exchange   \n",
       "\n",
       "                        Salary Estimate  \\\n",
       "0         $67K - $129K (Glassdoor est.)   \n",
       "1         $79K - $143K (Glassdoor est.)   \n",
       "2         $58K - $125K (Glassdoor est.)   \n",
       "3  Employer Provided Salary:$80K - $95K   \n",
       "4                                    -1   \n",
       "\n",
       "                                     Job Description Rating  \\\n",
       "0  Overview:\\nCharlie’s Produce - Who We Are\\n\\nC...    3.5   \n",
       "1  For nearly two decades, Zonar Systems has been...    3.2   \n",
       "2  PeopleReady, a TrueBlue company (NYSE: TBI), i...     -1   \n",
       "3  Ticketing system experience\\nExcellent trouble...     -1   \n",
       "4  Bachelor’s degree in Business Analytics, Stati...    3.7   \n",
       "\n",
       "                     Company Name     Location                     Size  \\\n",
       "0          Charlie's Produce\\n3.5  Seattle, WA   1001 to 5000 Employees   \n",
       "1              Zonar Systems\\n3.2  Seattle, WA     201 to 500 Employees   \n",
       "2                     PeopleReady   Tacoma, WA  5001 to 10000 Employees   \n",
       "3                       Zest City  Seattle, WA                  Unknown   \n",
       "4  Amazon Web Services, Inc.\\n3.7  Seattle, WA         10000+ Employees   \n",
       "\n",
       "            Founded               Type of ownership  \\\n",
       "0              1978               Company - Private   \n",
       "1              2001               Company - Private   \n",
       "2              1989  Subsidiary or Business Segment   \n",
       "3  Company - Public        Unknown / Non-Applicable   \n",
       "4              1994                Company - Public   \n",
       "\n",
       "                       Industry                  Sector  \\\n",
       "0                     Wholesale       Business Services   \n",
       "1  Computer Hardware & Software  Information Technology   \n",
       "2        Staffing & Outsourcing       Business Services   \n",
       "3                            -1                      -1   \n",
       "4                      Internet  Information Technology   \n",
       "\n",
       "                            Revenue  \n",
       "0  $500 million to $1 billion (USD)  \n",
       "1        $100 to $500 million (USD)  \n",
       "2         $50 to $100 million (USD)  \n",
       "3                                -1  \n",
       "4                $10+ billion (USD)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datawarehousemanager.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6539b53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c32da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d1a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8920ed56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22934dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3fe70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "535179d6",
   "metadata": {},
   "source": [
    "# SCRAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48adf6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da29f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_url = \"https://www.bls.gov/oes/current/oes_nat.htm\"\n",
    "tablehtml = pd.read_html(table_url)\n",
    "tableraw = tablehtml[0]\n",
    "tableraw = tableraw.drop([0, 1041])\n",
    "tableraw = tableraw.rename(columns = {\"Occupation title (click on the occupation title to view its profile)\": \"Occupation\", 'Employment': 'Number_of_Jobs_Listed','Employment per 1,000 jobs': 'Job_Frequency', 'Annual mean wage': 'Salary'})\n",
    "\n",
    "#table with grouped categories\n",
    "maincategories = tableraw[tableraw['Occupation code'].str[3].isin(['0'])].reset_index(drop = True)\n",
    "\n",
    "\n",
    "#cleaned up full table\n",
    "cleanedtable = tableraw.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "# cleanedtable\n",
    "maincategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c961ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "management_occupations = tableraw[tableraw['Occupation code'].str.contains('11-')].reset_index(drop = True)\n",
    "management_occupations = management_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "business_occupations = tableraw[tableraw['Occupation code'].str.contains('13-')].reset_index(drop = True)\n",
    "business_occupations = business_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "computer_occupations = tableraw[tableraw['Occupation code'].str.contains('15-')].reset_index(drop = True)\n",
    "computer_occupations = computer_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "engineering_occupations = tableraw[tableraw['Occupation code'].str.contains('17-')].reset_index(drop = True)\n",
    "engineering_occupations = engineering_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "science_occupations = tableraw[tableraw['Occupation code'].str.contains('19-')].reset_index(drop = True)\n",
    "science_occupations = science_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "social_occupations = tableraw[tableraw['Occupation code'].str.contains('21-')].reset_index(drop = True)\n",
    "social_occupations = social_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "legal_occupations = tableraw[tableraw['Occupation code'].str.contains('23-')].reset_index(drop = True)\n",
    "legal_occupations = legal_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "education_occupations = tableraw[tableraw['Occupation code'].str.contains('25-')].reset_index(drop = True)\n",
    "education_occupations = education_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "arts_occupations = tableraw[tableraw['Occupation code'].str.contains('27-')].reset_index(drop = True)\n",
    "arts_occupations = arts_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "healthcare_occupations = tableraw[tableraw['Occupation code'].str.contains('29-')].reset_index(drop = True)\n",
    "healthcare_occupations = healthcare_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "healthcaresup_occupations = tableraw[tableraw['Occupation code'].str.contains('31-')].reset_index(drop = True)\n",
    "healthcaresup_occupations = healthcaresup_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "protective_occupations = tableraw[tableraw['Occupation code'].str.contains('33-')].reset_index(drop = True)\n",
    "protective_occupations = protective_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "food_occupations = tableraw[tableraw['Occupation code'].str.contains('35-')].reset_index(drop = True)\n",
    "food_occupations = food_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "building_occupations = tableraw[tableraw['Occupation code'].str.contains('37-')].reset_index(drop = True)\n",
    "building_occupations = building_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "personalcare_occupations = tableraw[tableraw['Occupation code'].str.contains('39-')].reset_index(drop = True)\n",
    "personalcare_occupations = personalcare_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "sales_occupations = tableraw[tableraw['Occupation code'].str.contains('41-')].reset_index(drop = True)\n",
    "sales_occupations = sales_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "office_occupations = tableraw[tableraw['Occupation code'].str.contains('43-')].reset_index(drop = True)\n",
    "office_occupations = office_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "farming_occupations = tableraw[tableraw['Occupation code'].str.contains('45-')].reset_index(drop = True)\n",
    "farming_occupations = farming_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "construction_occupations = tableraw[tableraw['Occupation code'].str.contains('47-')].reset_index(drop = True)\n",
    "construction_occupations = construction_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "maintenance_occupations = tableraw[tableraw['Occupation code'].str.contains('49-')].reset_index(drop = True)\n",
    "maintenance_occupations = maintenance_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "production_occupations = tableraw[tableraw['Occupation code'].str.contains('51-')].reset_index(drop = True)\n",
    "production_occupations = production_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "transportation_occupations = tableraw[tableraw['Occupation code'].str.contains('53-')].reset_index(drop = True)\n",
    "transportation_occupations = transportation_occupations.loc[:, ['Occupation', 'Number_of_Jobs_Listed', 'Job_Frequency', 'Salary']]\n",
    "\n",
    "# test = transportation_occupations.to_dict('records')\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ae0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvpath = \"../resources/choroplethedit.csv\"\n",
    "wagecsv = pd.read_csv(csvpath)\n",
    "softwarecsv = wagecsv[wagecsv['Occupation text'].str.contains(\"Software\")]\n",
    "computercsv = wagecsv[wagecsv['Occupation text'].str.contains(\"Computer\")]\n",
    "newdf = pd.concat([computercsv, softwarecsv])\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94188e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Database Admin', 'Big Data Software Engineer', 'Quantitative Analyst', 'IT Systems Analyst', \n",
    "             'Data Analyst', 'Business Intelligence Analyst', 'Data Architect', 'Business Systems Analyst', \n",
    "             'Machine Learning Engineer', 'Data Engineer', 'Data Scientist', 'Machine Learning Scientist', \n",
    "             'Business Intelligence Developer', 'Logistics Analyst', 'Marketing Analyst', 'Data Warehouse Manager', \n",
    "             'Statistician', 'Data Storyteller', 'Database Administrator', 'Database Manager', 'Data Modeler']\n",
    "jobnumbers = [i for i in range(21)]\n",
    "statenumbers = [i for i in range(50)]\n",
    "# dfca['Code'] = dfca['Area text'] + dfca['Job Category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1abf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonational = newdf.loc[newdf['Area text'] != 'National']\n",
    "# df=nonational.sort_values('Occupation text')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0131c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_list = nonational['Occupation text'].unique()\n",
    "# for x in occupation_list:\n",
    "    \n",
    "#     print(x)\n",
    "len(occupation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgroup=bigboi.groupby(['Occupation text','Area text'])\n",
    "# bgroup[\"Job characteristic code\"].count().reset_index().to_csv(\"../resources/IgotchuAndrew_sj.csv\")\n",
    "bggroup2 = bgroup[\"Job characteristic code\"].count().reset_index().sort_values('Occupation text')\n",
    "bggroup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6608e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "states = [dfal, dfak, dfaz, dfar, dfca, dfco, dfct, dfde, dfdc, dffl, dfga, dfhi, dfid, dfil, dfin, dfia, dfks, dfky, dfla, dfme, dfmd, dfma, dfmi, dfmn, dfms, dfmo, dfmt, dfne, dfnv, dfnh, dfnj, dfnm, dfny, dfnc, dfnd, dfoh, dfok, dfor, dfpa, dfri, dfsc, dfsd, dftn, dftx, dfut, dfvt, dfva, dfwa, dfwv, dfwi, dfwy]    \n",
    "# teststate = dfal.groupby(['Occupation text'])  \n",
    "# teststate2 = teststate[\"Job characteristic code\"].count().reset_index().sort_values('Occupation text').set_index('Occupation text')\n",
    "# testdict = teststate2.to_dict()\n",
    "# testdict\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0816dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alabama = 0\n",
    "# Alaska = 0\n",
    "# Arizona = 0\n",
    "# Arkansas = 0\n",
    "# California = 0\n",
    "# Colorado = 0\n",
    "# Connecticut = 0\n",
    "# Delaware = 0\n",
    "# DistrictColumbia = 0\n",
    "# Florida = 0\n",
    "# Georgia = 0\n",
    "# Hawaii = 0\n",
    "# Idaho = 0\n",
    "# Illinois = 0\n",
    "# Indiana = 0\n",
    "# Iowa =  0\n",
    "# Kansas = 0\n",
    "# Kentucky = 0\n",
    "# Louisiana = 0\n",
    "# Maine = 0\n",
    "# Maryland = 0\n",
    "# Massachusetts = 0\n",
    "# Michigan = 0\n",
    "# Minnesota = 0\n",
    "# Mississippi = 0\n",
    "# Missouri = 0\n",
    "# Montana = 0\n",
    "# Nebraska = 0\n",
    "# Nevada = 0\n",
    "# NewHampshire = 0\n",
    "# NewJersey = 0\n",
    "# NewMexico = 0\n",
    "# NewYork = 0\n",
    "# NorthCarolina = 0\n",
    "# NorthDakota = 0\n",
    "# Ohio = 0\n",
    "# Oklahoma = 0\n",
    "# Oregon = 0\n",
    "# Pennsylvania = 0\n",
    "# RhodeIsland = 0\n",
    "# SouthCarolina = 0\n",
    "# SouthDakota = 0\n",
    "# Tennessee = 0\n",
    "# Texas = 0\n",
    "# Utah = 0\n",
    "# Vermont = 0\n",
    "# Virginia = 0\n",
    "# Washington = 0\n",
    "# WestVirginia = 0\n",
    "# Wisconsin = 0\n",
    "# Wyoming = 0"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0507ca4863d74825e19143f64061a0d98fde3c42611721bd9ba5ee5b8cfcb010"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
